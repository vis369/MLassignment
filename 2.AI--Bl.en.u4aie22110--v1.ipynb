{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd736efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: medium\n",
      "Euclidean result: 2.8284271247461903\n",
      "Manhattan result: 4\n",
      "Encoded variables : [0, 1, 2, 3, 4, 5, 0, 1, 4, 3]\n",
      "Encoded_vectors\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "Category to index mapping : {'sheep': 0, 'cat': 1, 'dog': 2, 'tiger': 3, 'hen': 4, 'goat': 5}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# if we need any vectors as input we can give here \n",
    "def vec():\n",
    "    vectors = []\n",
    "    print(\"How many vectors do you want?\")\n",
    "    num = int(input())\n",
    "    for i in range(num):\n",
    "        print(\"Enter vectors\", i + 1)\n",
    "        row = 1  # Adjust if multiple rows needed\n",
    "        print(\"Enter the number of columns you need:\")\n",
    "        col = int(input())\n",
    "        vector = input_vector(row, col)\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "#creating vectors by rows and columns\n",
    "def input_vector(row, col):\n",
    "    vector = []\n",
    "    for _ in range(row):\n",
    "        vector_row = []\n",
    "        for _ in range(col):\n",
    "            inp = int(input())\n",
    "            vector_row.append(inp)\n",
    "        vector.append(vector_row)\n",
    "    return vector\n",
    "\n",
    "#calculating manhattan distance which is popular\n",
    "\n",
    "def manhattan(v1, v2):\n",
    "    if len(v1) != len(v2):   #checking if it is possible for calcullating \n",
    "        return math.inf  # Return a very large value to indicate incomparability\n",
    "    sum_of_num = 0\n",
    "    for i in range(len(v1)):\n",
    "        sum_of_num += abs(v2[i] - v1[i])  # Taking absolute value here and calculation\n",
    "    return sum_of_num\n",
    "\n",
    "def euclidean_distance(v1, v2):  #calculating the euclidean distance \n",
    "    if len(v1) != len(v2):\n",
    "        return math.inf  # Return a very large value to indicate incomparability\n",
    "    sum_of_squares = 0\n",
    "    for i in range(len(v1)):\n",
    "        sum_of_squares += (v1[i] - v2[i]) ** 2 # using the formuulae for euclidean distance\n",
    "    return math.sqrt(sum_of_squares)\n",
    "\n",
    "# get neighbour for calculating the distance  for Knn classifier\n",
    "def get_neighbors(training_data, test_instance):\n",
    "    distances = []\n",
    "    for train_data in training_data:\n",
    "        distance = euclidean_distance(train_data[0], test_instance)  # using Euclidean distance for calculating the distance\n",
    "        distances.append((distance, train_data[1]))\n",
    "    return distances  # returning the distance \n",
    "\n",
    "# Knn classifier using get neighbour and K value we can find the nearest neighbor\n",
    "# taking the training data , traning instance and k value as imports\n",
    "def Knn_classifier(training_data, test_instance, k_value):\n",
    "    neighbors = get_neighbors(training_data,test_instance)\n",
    "    neighbors.sort()  # using sort function\n",
    "    nearest_neighbors = neighbors[:k_value]  # using slice for  taking top neighbors using K value\n",
    "    classes = [neighbor[1] for neighbor in nearest_neighbors] # selecting the first nearest  neighbor\n",
    "    class_counter = Counter(classes  #counter is used for counting how many times a same label will come \n",
    "    most_common_class = class_counter.most_common(1)[0][0]  #it will select the most common \n",
    "    return most_common_class # return the most_common_class\n",
    "\n",
    "                            \n",
    "# label_encoding which converts labels into numbers                         \n",
    "def label_encoded_categorial(variables): # taking varibles list as input\n",
    "    label_map={}  #dictionary for correctly mapping labels into numbers \n",
    "    encoded_variables = [] # using the ;list we will show numbering of the labels at the end\n",
    "    label_counter = 0   #this is label counter for numbering the labels\n",
    "    for var in variables:\n",
    "        if var not in label_map:\n",
    "            label_map[var] = label_counter\n",
    "            label_counter += 1\n",
    "        encoded_variables.append(label_map[var])\n",
    "    return encoded_variables  #returning the encoded varibles\n",
    "\n",
    "                            \n",
    " #One hot encodding for converting  labels into binary form\n",
    "def one_hot_coding(variables):\n",
    "    unique_categories = list(set(variables)) # set is used to not allow any duplicates like repetation\n",
    "    category_to_index = {category: i for i, category in enumerate(unique_categories)}  # here we use same dictionary for numbering after we will convert them into binary form and store in the list\n",
    "    encoded_labels = []  #list for displaying the binary vectors\n",
    "    for var in variables:\n",
    "        binary_vector = [0] * len(unique_categories) # creating the binary vector with zeros before converting\n",
    "        binary_vector[category_to_index[var]] = 1  #converting labels into binary vector using dictionary\n",
    "        encoded_labels.append(binary_vector)  #adding the binary vector to the list\n",
    "    return encoded_labels,category_to_index # returning the list and category index because how we use sictionary for numbering\n",
    "\n",
    "\n",
    "v1 = [1, 2]\n",
    "v2 = [3, 4]\n",
    "result1 = euclidean_distance(v1, v2)\n",
    "result2 = manhattan(v1, v2)\n",
    "\n",
    "# Example usage:\n",
    "training_data = [([150, 50], 'medium'), ([155, 55], 'medium'), ([160, 60], 'large'), ([161, 59], 'large'), ([158, 65], 'large')]\n",
    "test_instance = [157, 54]\n",
    "k_value = 1 # Define k_value before using it\n",
    "categorial_variables = ['dog','cat','hen','goat','sheep','tiger','dog','cat','sheep','goat']\n",
    "encoded_variables = label_encoded_categorial(categorial_variables)\n",
    "result = Knn_classifier(training_data, test_instance, k_value)\n",
    "encoded, category_to_index = one_hot_coding(categorial_variables)\n",
    "print(\"Predicted class:\", result)\n",
    "print(\"Euclidean result:\", result1)\n",
    "print(\"Manhattan result:\", result2)\n",
    "print(\"Encoded variables :\", encoded_variables)\n",
    "print(\"Encoded_vectors\")\n",
    "for row in encoded:\n",
    "    print(row)\n",
    "print(\"Category to index mapping :\", category_to_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0433e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d64c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
